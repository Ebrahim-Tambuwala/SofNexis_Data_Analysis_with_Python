{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc617486-c996-4055-b193-05fe376f0d55",
   "metadata": {},
   "source": [
    "# Problem Definition & Setup\n",
    "\n",
    "### üéØ Objective\n",
    "The goal of this project is to build a **machine learning model** that predicts whether a passenger survived the Titanic disaster. This is a **classification problem** because the output (**Survived**) has only two possible categories:\n",
    "\n",
    "* **1** ‚Üí Passenger survived\n",
    "* **0** ‚Üí Passenger did not survive\n",
    "\n",
    "### üìå Problem Type\n",
    "problem_type = \"classification\"\n",
    "\n",
    "### üéØ Target Variable\n",
    "target_column = \"Survived\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739761d8-5a4f-4af1-9ce1-5ef0bfc5db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (887, 8)\n",
      "\n",
      "First 5 rows:\n",
      "    Survived  Pclass                                               Name  \\\n",
      "0         0       3                             Mr. Owen Harris Braund   \n",
      "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
      "2         1       3                              Miss. Laina Heikkinen   \n",
      "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
      "4         0       3                            Mr. William Henry Allen   \n",
      "\n",
      "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
      "0    male  22.0                        1                        0   7.2500  \n",
      "1  female  38.0                        1                        0  71.2833  \n",
      "2  female  26.0                        0                        0   7.9250  \n",
      "3  female  35.0                        1                        0  53.1000  \n",
      "4    male  35.0                        0                        0   8.0500  \n",
      "\n",
      "Missing values:\n",
      " Survived                   0\n",
      "Pclass                     0\n",
      "Name                       0\n",
      "Sex                        0\n",
      "Age                        0\n",
      "Siblings/Spouses Aboard    0\n",
      "Parents/Children Aboard    0\n",
      "Fare                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Basic checks\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\\n\", df.head())\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9001deb9-cc86-4b12-99e8-e54696517b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                             Mr. Owen Harris Braund   \n",
       "1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2           1       3                              Miss. Laina Heikkinen   \n",
       "3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4           0       3                            Mr. William Henry Allen   \n",
       "..        ...     ...                                                ...   \n",
       "882         0       2                               Rev. Juozas Montvila   \n",
       "883         1       1                        Miss. Margaret Edith Graham   \n",
       "884         0       3                     Miss. Catherine Helen Johnston   \n",
       "885         1       1                               Mr. Karl Howell Behr   \n",
       "886         0       3                                 Mr. Patrick Dooley   \n",
       "\n",
       "        Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0      male  22.0                        1                        0   7.2500  \n",
       "1    female  38.0                        1                        0  71.2833  \n",
       "2    female  26.0                        0                        0   7.9250  \n",
       "3    female  35.0                        1                        0  53.1000  \n",
       "4      male  35.0                        0                        0   8.0500  \n",
       "..      ...   ...                      ...                      ...      ...  \n",
       "882    male  27.0                        0                        0  13.0000  \n",
       "883  female  19.0                        0                        0  30.0000  \n",
       "884  female   7.0                        1                        2  23.4500  \n",
       "885    male  26.0                        0                        0  30.0000  \n",
       "886    male  32.0                        0                        0   7.7500  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de838b-9840-44ed-8b2a-9680622aa2c7",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "The dataset contains information about **887 Titanic passengers** with the following key features:\n",
    "\n",
    "* **Pclass** ‚Üí Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "* **Name** ‚Üí Passenger name\n",
    "* **Sex** ‚Üí Gender\n",
    "* **Age** ‚Üí Age in years\n",
    "* **Siblings/Spouses Aboard** ‚Üí Number of siblings/spouses aboard\n",
    "* **Parents/Children Aboard** ‚Üí Number of parents/children aboard\n",
    "* **Fare** ‚Üí Ticket price\n",
    "* **Survived** ‚Üí Target label (0 = No, 1 = Yes)\n",
    "\n",
    "### Dataset Shape\n",
    "There are:\n",
    "* **887** rows (passengers)\n",
    "* **8** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a788d105-813e-45a6-b3b9-a24715d7dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name Title  Title_encoded\n",
      "0                             Mr. Owen Harris Braund    Mr              0\n",
      "1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   Mrs              2\n",
      "2                              Miss. Laina Heikkinen  Miss              1\n",
      "3        Mrs. Jacques Heath (Lily May Peel) Futrelle   Mrs              2\n",
      "4                            Mr. William Henry Allen    Mr              0\n",
      "\n",
      "Missing values:\n",
      " Survived                   0\n",
      "Pclass                     0\n",
      "Name                       0\n",
      "Sex                        0\n",
      "Age                        0\n",
      "Siblings/Spouses Aboard    0\n",
      "Parents/Children Aboard    0\n",
      "Fare                       0\n",
      "FamilySize                 0\n",
      "IsAlone                    0\n",
      "Sex_encoded                0\n",
      "Title                      0\n",
      "Title_encoded              0\n",
      "dtype: int64\n",
      "\n",
      "Final shape: (887, 13)\n"
     ]
    }
   ],
   "source": [
    "# 1. Fill missing Age with median\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# 2. Create FamilySize\n",
    "df['FamilySize'] = df['Siblings/Spouses Aboard'] + df['Parents/Children Aboard'] + 1\n",
    "\n",
    "# 3. Create IsAlone feature\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# 4. Encode Sex\n",
    "df['Sex_encoded'] = df['Sex'].map({'male':0, 'female':1})\n",
    "\n",
    "# 5. Extract Title (FIXED REGEX)\n",
    "df['Title'] = df['Name'].str.extract(r'([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# 6. Group rare titles\n",
    "rare_titles = ['Lady', 'Countess','Capt', 'Col','Don', 'Dr', \n",
    "               'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "\n",
    "df['Title'] = df['Title'].replace({\n",
    "    'Mlle': 'Miss',\n",
    "    'Ms': 'Miss',\n",
    "    'Mme': 'Mrs'\n",
    "})\n",
    "\n",
    "df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# 7. Encode Title\n",
    "title_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4}\n",
    "df['Title_encoded'] = df['Title'].map(title_mapping)\n",
    "\n",
    "# 8. Confirm\n",
    "print(df[['Name','Title','Title_encoded']].head())\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nFinal shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217555f5-61d6-4bdd-87b2-0e14ce07cee9",
   "metadata": {},
   "source": [
    "# Now Train / Test Split (Critical Step)\n",
    "\n",
    "Now we‚Äôll split the data so that:\n",
    "\n",
    "* **80%** ‚Üí **Training data** (model learns here)\n",
    "* **20%** ‚Üí **Testing data** (used **ONLY** to evaluate)\n",
    "\n",
    "We also use `stratify=y` so the survival ratio remains balanced.\n",
    "\n",
    "> **Note:** We will only use **numerical model-ready features** ‚Äî not raw text columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c564fb-5438-4097-846e-28787cd2927e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 709\n",
      "Testing samples: 178\n",
      "\n",
      "X_train shape: (709, 9)\n",
      "X_test shape: (178, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select final features\n",
    "features = [\n",
    "    'Pclass', 'Sex_encoded', 'Age',\n",
    "    'Siblings/Spouses Aboard', 'Parents/Children Aboard',\n",
    "    'Fare', 'FamilySize', 'IsAlone', 'Title_encoded'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['Survived']\n",
    "\n",
    "# Train‚ÄìTest Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])\n",
    "print(\"\\nX_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9a011-645f-48b9-b3c7-aca49f5c85ae",
   "metadata": {},
   "source": [
    "# Train 2 Models (Baseline + Powerful)\n",
    "\n",
    "We‚Äôll do this in a clean, human-style workflow:\n",
    "\n",
    "* **‚úî Model-1: Logistic Regression**\n",
    "  *(Simple baseline ‚Äî fast, interpretable)*\n",
    "\n",
    "* **‚úî Model-2: Random Forest**\n",
    "  *(More powerful ‚Äî usually performs better)*\n",
    "\n",
    "### üìã We‚Äôll:\n",
    "1. **Train** the model on *training data only*\n",
    "2. **Predict** on *test data only*\n",
    "3. **Measure** Accuracy & F1-Score\n",
    "\n",
    "| Step | Meaning |\n",
    "| :--- | :--- |\n",
    "| **`fit()`** | Model learns patterns from training data |\n",
    "| **`predict()`** | Model guesses survival on unseen test data |\n",
    "| **`accuracy_score`** | Measures % correct |\n",
    "| **`f1_score`** | Balances precision & recall |\n",
    "| **`classification_report`** | Shows precision/recall per class |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1fba3d-870b-4004-a6c6-8161a8020a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n",
      "Accuracy: 0.8034\n",
      "F1 Score: 0.7407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       109\n",
      "           1       0.76      0.72      0.74        69\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.79      0.79       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n",
      "\n",
      "Random Forest Results\n",
      "Accuracy: 0.7584\n",
      "F1 Score: 0.695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       109\n",
      "           1       0.68      0.71      0.70        69\n",
      "\n",
      "    accuracy                           0.76       178\n",
      "   macro avg       0.75      0.75      0.75       178\n",
      "weighted avg       0.76      0.76      0.76       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# -------- Logistic Regression --------\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "log_acc = accuracy_score(y_test, log_pred)\n",
    "log_f1 = f1_score(y_test, log_pred)\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "print(\"Accuracy:\", round(log_acc, 4))\n",
    "print(\"F1 Score:\", round(log_f1, 4))\n",
    "print(classification_report(y_test, log_pred))\n",
    "\n",
    "\n",
    "# -------- Random Forest --------\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "\n",
    "print(\"\\nRandom Forest Results\")\n",
    "print(\"Accuracy:\", round(rf_acc, 4))\n",
    "print(\"F1 Score:\", round(rf_f1, 4))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec252d7-36e0-4362-bea5-20f0fb517a13",
   "metadata": {},
   "source": [
    "# Feature Importance & Model Interpretation\n",
    "\n",
    "The goal of this step is to understand **which features contributed the most** to predicting survival on the Titanic. This helps convert model results into **real-world insights**, rather than just numbers.\n",
    "\n",
    "I analysed feature importance from:\n",
    "* **‚úî Logistic Regression** (coefficients)\n",
    "* **‚úî Random Forest Classifier** (feature importance scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7142ab6-2c05-4192-809b-306fd727296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature  Coefficient\n",
      "1              Sex_encoded     2.158903\n",
      "8            Title_encoded     0.470261\n",
      "4  Parents/Children Aboard     0.036287\n",
      "5                     Fare     0.006089\n",
      "2                      Age    -0.046345\n",
      "6               FamilySize    -0.287426\n",
      "3  Siblings/Spouses Aboard    -0.321162\n",
      "7                  IsAlone    -0.362250\n",
      "0                   Pclass    -0.928149\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': log_model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94dda5b-8e5f-49fd-ac27-4893506a9eae",
   "metadata": {},
   "source": [
    "## Logistic Regression ‚Äì Feature Influence\n",
    "\n",
    "In Logistic Regression, **positive coefficients** increase the probability of survival, while **negative coefficients** decrease it.\n",
    "\n",
    "### üìä From my model:\n",
    "\n",
    "| Feature | Effect | Impact on Survival |\n",
    "| :--- | :---: | :--- |\n",
    "| **Sex_encoded** (female = 1) | üî∫ | **Strong positive** ‚Äî females much more likely to survive |\n",
    "| **Title_encoded** | üî∫ | Titles like Mrs/Miss had higher survival than Mr |\n",
    "| **Fare** | üî∫ | Higher fare ‚Üí more survival (wealthier passengers likely in safer cabins) |\n",
    "| **Parents/Children Aboard** (Parch) | üî∫ | Small positive effect |\n",
    "| **Age** | üîª | Older passengers slightly less likely to survive |\n",
    "| **FamilySize** | üîª | Large families had lower survival odds |\n",
    "| **Siblings/Spouses Aboard** (SibSp) | üîª | More companions ‚Üí lower survival chance |\n",
    "| **IsAlone** | üîª | Alone passengers slightly less likely |\n",
    "| **Pclass** (3rd class) | üîª | **Strong negative** ‚Äî 3rd class survival lowest |\n",
    "\n",
    "### ‚úî Key Interpretation (Simple & Clear)\n",
    "* **Gender is the strongest predictor** ‚Äî females survived far more than males.\n",
    "* **Passenger class matters a lot** ‚Äî 1st class had a clear survival advantage.\n",
    "* **Higher ticket fare** increases survival probability.\n",
    "* **Travelling with very large families** reduced survival chances.\n",
    "* **Age** has a moderate negative impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954e5f65-9584-4796-8468-fa36ce8e50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature  Importance\n",
      "5                     Fare    0.249942\n",
      "2                      Age    0.240470\n",
      "1              Sex_encoded    0.178903\n",
      "8            Title_encoded    0.142018\n",
      "0                   Pclass    0.082390\n",
      "6               FamilySize    0.049359\n",
      "3  Siblings/Spouses Aboard    0.032306\n",
      "4  Parents/Children Aboard    0.015426\n",
      "7                  IsAlone    0.009185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(rf_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc551b2f-fc55-42f9-8231-bb63a5c74d88",
   "metadata": {},
   "source": [
    "# Random Forest ‚Äì Feature Importance Ranking\n",
    "\n",
    "Random Forest also confirms the top predictive factors:\n",
    "\n",
    "| Rank | Feature | Insight |\n",
    "| :--- | :--- | :--- |\n",
    "| **1** | **Fare** | Higher fare = better survival |\n",
    "| **2** | **Age** | Younger passengers had better survival rates |\n",
    "| **3** | **Sex_encoded** | Females more likely to survive |\n",
    "| **4** | **Title_encoded** | Social status strongly linked to survival |\n",
    "| **5** | **Pclass** | 1st class > 2nd > 3rd survival |\n",
    "| **6‚Äì9** | FamilySize, SibSp, Parch, IsAlone | Smaller influence |\n",
    "\n",
    "### ‚úî Combined Interpretation\n",
    "Both models strongly agree:\n",
    "\n",
    "* ‚≠ê **Gender, Fare, Title, and Passenger Class** are the best predictors of survival.\n",
    "* ‚≠ê **Women and higher-class passengers** had clear priority in rescue.\n",
    "* ‚≠ê **Wealth (Fare)** also correlates with survival.\n",
    "* ‚≠ê **Travelling alone or with many dependents** reduced survival chances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d6d3b31-0a44-4f35-a9e8-91a20773ed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.695035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1 Score\n",
       "0  Logistic Regression  0.803371  0.740741\n",
       "1        Random Forest  0.758427  0.695035"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model':['Logistic Regression','Random Forest'],\n",
    "    'Accuracy':[log_acc, rf_acc],\n",
    "    'F1 Score':[log_f1, rf_f1]\n",
    "})\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472a6b0-a0b2-425b-986c-7aeeb15ae940",
   "metadata": {},
   "source": [
    "## Model Performance Comparison\n",
    "\n",
    "| Model | Accuracy | F1-Score | Notes |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Logistic Regression** | **80.3%** | **0.74** | ‚úî Best performer |\n",
    "| **Random Forest** | 75.8% | 0.69 | Slightly weaker |\n",
    "\n",
    "### üéØ Conclusion\n",
    "The **Logistic Regression** model performed best in my experiment.\n",
    "\n",
    "* The model predicts survival with **~80% accuracy**, which is reasonable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3393e-5917-41e6-b4f3-36e8b4eac74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
